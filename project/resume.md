## AgileHub

### 대학생이 Jira를 처음 사용할 때 겪은 어려움은 뭐가 있나요?

```text
Jira는 다양한 기능과 옵션을 제공하는데, 이를 한 번에 이해하는 것은 쉽지 않습니다. 특히 처음 사용자는 이슈 유형, 백로그 관리, 에픽과 스프린트 등 용어 자체도 생소할 수 있습니다.
그리고 이슈 관리도 복잡하고, 팀 협업을 안해봤으면 이 협업도구의 기능에 대해 제대로 이해못해 어려움을 겪을 수 있습니다. 
```

### 백로그관리와 스프린트관리의 차이점이 뭐죠?

```text
백로그는 <장기적인 프로젝트의 전반적인 작업>을 관리하는 도구로, 제품 소유자가 주로 <우선순위>를 설정하고 관리합니다.

반면에, 스프린트 관리는 백로그에서 우선순위가 높은 작업을 <선택하여 일정 기간 동안 집중적으로 실행>하는 과정입니다. 
스프린트는 보통 <1주에서 4주 정도의 짧은 기간 동안 진행>되며, 이 기간 동안 팀은 사전에 설정된 목표를 달성하는 데 집중합니다. 

즉, 백로그 관리는 프로젝트의 <전체적인 작업 목록을 관리>하고, 스프린트 관리는 <단기 목표를 설정>하고 실행하는 과정이라고 말씀드릴 수 있습니다.
```

### 에픽, 스토리, 테스크 차이점이 뭐죠?

```text
에픽은 <가장 큰 단위>의 작업입니다. 
에픽은 하나의 <큰 목표>나 기능을 의미하며, 보통 <여러 스프린트>에 걸쳐 완성되는 <긴 작업>입니다.

스토리는 에픽을 세분화한 것으로, <사용자 관점에서 요구되는 특정 기능>이나 작업을 설명합니다. 
보통 <한 스프린트 내에서 완료할 수 있는 작업 단위>로, 사용자 경험에 초점을 맞추고 있습니다.

테스크는 스토리를 더 세부적으로 나눈 것입니다. 팀원들이 <스토리를 실제로 구현하기 위해 필요한 구체적인 작업들>이 테스크입니다.
테스크는 아주 세부적인 단위로, 실제 개발자나 팀원이 실행할 수 있는 수준의 작업을 의미합니다.
```


### 애자일 방법론이 뭐죠?

```text
애자일이란 우선 만들고 보여주고 평가를 받고 회고를 하며, 방향을 고쳐나가는 것을 반복하며 MVP를 개발하고 
이 과정을 모두가 함께 참여하며 누구나 볼 수 있게 이 과정을 시각화하면서 피드백 주기를 점점 짧게 만들고자 노력하는 것입니다.
```

### JDBC 타임아웃이란 무엇인가요?

```text
JDBC 타임아웃은 데이터베이스와의 연결에서 특정 작업(연결, 쿼리 실행 등)이 일정 시간 안에 완료되지 않으면 예외를 발생시키고 작업을 중단하는 설정입니다.
```

### JDBC에서 타임아웃을 설정하는 방법에는 어떤 것들이 있나요?

```text
DriverManager를 통한 커넥션 타임아웃과 Statement나 PreparedStatement를 통한 쿼리 실행 타임아웃이 있습니다.
```

### JDBC 타임아웃을 설정하지 않으면 발생할 수 있는 문제는 무엇인가요?

```text
타임아웃을 설정하지 않으면 연결이나 쿼리 실행이 무기한 대기 상태로 남아, 서버 리소스가 불필요하게 소모될 수 있고,
외부 네트워크나 데이터베이스 서버에 문제가 생긴 경우, 애플리케이션이 해당 작업을 무기한 기다리게 되어 장애로 이어질 위험이 있습니다.
```

### JDBC 타임아웃이 발생했을 때 예외 처리를 어떻게 해야 하나요?

```text
JDBC 타임아웃이 발생하면 SQLTimeoutException이 던져지며,
예외를 캐치해서 로그를 남기거나 사용자에게 적절한 오류 메시지를 보여주며, 연결을 다시 시도하거나 백엔드에서 다른 처리를 할 수 있습니다.
 예를 들어, 타임아웃을 감지했을 때 연결을 재시도하거나 다른 데이터베이스 서버로 페일오버(failover)할 수 있는 로직을 작성할 수 있습니다.
```
### JDBC 타임아웃을 효과적으로 관리하기 위한 전략은 무엇인가요?

```text
적절한 타임아웃 값 설정하거나, 쿼리 자체를 최적화하거나 인덱스를 추가하거나 
리트라이 로직이나 
타임아웃이 발생하는 작업을 비동기적으로 처리할것 같습니다. 
```

### 드라이빙 테이블이 뭔가요?

```text
조인 쿼리에서 가장 먼저 읽히는 테이블로, 기준 테이블입니다.
```

### from에 서브쿼리를 사용했는 데 왜 조회속도가 단축되었나요?

```text
서브쿼리는 FROM 절 내에서 필터링된 데이터 또는 필요한 칼럼만을 미리 추출하는 역할을 합니다. 
즉, 서브쿼리에서 먼저 필터링하여 결과 집합을 작게 만든 뒤, 그 결과에 대해 조인이나 다른 연산을 수행하므로, 최종적으로 조회해야 하는 데이터의 양이 줄어들게 됩니다.
```

### QueryDsl이 from 절 사용이 불가능하다고 했는데 다른 해결 방법이 있는데 혹시 아시나요?

```text
- id검색 쿼리, 조회쿼리를 나눠서 실행합니다. 단, 이는 대용량 데이터를 조회할 때 DB마다의 MAX된 IN절 제한으로 불가능할 수도 있습니다.
- 네이티브쿼리, JDBC Template
- QueryDSL의 JPASQLQuery를 사용하여 네이티브 SQL과 유사한 기능을 구현할 수 있습니다. 
  단, from절 sub-query외부에서는 QClass의 형태로 참조가 불가능합니다.
```

### 네이티브 쿼리와 projection이 뭐죠?

```text
네이티브는 말 그대로 특정데이터베이스의 sql언어를 직접 string으로 작성하는거라 db에 종속적이고,
프로젝션은 dto를 통해 특정 칼럼만 받는 방식입니다. 
```


## BookChallenge

### 서버리소스를 늘렸는데 왜 유의미한 변화가 없었나요?
```text
각 트랜잭션이 사용하는 CPU 사용량이 0.05프로, 메모리 사용량을 5MB로 가정했을 때 TPS 200의 목표를 도달하기 위해서는 충분히 1CPU 1GB 램으로도 가능하다는 사실을 알게됐습니다.  
```

### 그 0.05랑 5MB는 어디서 혹은 어떻게 생각해서 나온 수치인가요?

```text
이 수치는 실제 트래픽 상황에서 각 트랜잭션의 평균적인 리소스 사용량을 추정한 값입니다. 이를 추정하기 위해서는 다음과 같은 과정을 거쳤습니다

CPU 사용량의 경우, 일반적으로 서버가 특정 요청을 처리하는 데 소요되는 CPU 자원을 모니터링한 후, NGrinder와 같은 부하 테스트 도구를 통해 트랜잭션 당 평균 CPU 사용량을 추정했습니다. 
다수의 요청을 처리하면서 평균적으로 각 트랜잭션이 0.05%의 CPU 자원을 소비한다는 결론을 얻었습니다.
 
주로 메모리 프로파일링 도구를 사용하여 트랜잭션 처리 시 사용되는 메모리 양을 측정했고, 각 트랜잭션 당 평균적으로 5MB 정도를 사용한다고 판단했습니다.
```

### filesort가 왜 성능이 안좋죠?

```text
filesort는 메모리 내에서 정렬을 처리하지 못할 때, 데이터를 디스크에 임시 파일로 저장한 후 정렬 작업을 수행합니다. 
메모리 접근보다 디스크 접근이 훨씬 느리기 때문에, 파일 시스템을 통해 정렬을 수행하는 것은 상당한 시간 지연을 유발합니다. 
```

### 인덱스 테이블에서 쓰기 작업의 성능 저하가 왜 일어나나요?

```text
- 데이터가 변경될 때마다 관련 인덱스도 함께 업데이트해야 합니다. 이는 추가적인 I/O 작업을 필요로 합니다.
- 대량의 데이터 삽입이나 삭제 시 인덱스 구조를 재조정해야 할 수 있습니다.
- 동시성 제어를 위해 인덱스에 대한 잠금이 발생하여 다른 작업들이 대기해야 할 수 있습니다.
- B-트리 기반 인덱스의 경우, 새 데이터 삽입 시 페이지 분할이 필요할 수 있어 추가 작업이 발생합니다.
```

### 인덱스 풀 스캔과 인덱스 레인지 스캔 차이가 뭐죠?

```text

```

### No-OFFSET 방식의 단점은 뭐가 있을까요?

```text
- UI 단에서 페이지 번호로 요구하는 비즈니스 사항에서 무한스크롤로 방식인 No-OFFSET은 불가능합니다.
- 총 페이지 수를 계산하기 어렵기 때문에 사용자가 특정 페이지 번호로 직접 이동하기 어려울 수 있습니다.
```

### No-OFFSET 방식말고 더 개선할 점은 없을까요?  

```text
책 검색 API에서도 비슷한 요구사항인 페이징 처리가 필요했었는데, 이때는 OFFSET 방식으로 개선해보기로 정했습니다.

책 검색 API에서는 다양한 조건이 들어갑니다. 조건절에 여러개의 조건이 들어가면 성능이 급격히 안좋아지는 현상이 발생했습니다.

테이블 풀 스캔에 duration은 5.364 초 입니다. where 절의 책이름과 페이지수 칼럼 각각에 이미 인덱스를 생성한 상태에도 불구하고, 테이블 풀 스캔으로 진행되었습니다. 
당연하게도 조건이 한개일때는 적용되지만, 두개가 같이 들어가니 인덱스 테이블을 더이상 타지 않았습니다.

주로 책 이름과 페이지 카운트만 검색한다고 가정하고, 복합인덱스를 생성할 때 자주 검색되는 조건인 책 이름 칼럼을 앞 순위에 배치하여 생성하여 성능을 5초에서 1초대로 개선했습니다.
또한, 책이름, 페이지카운트 순서인 인덱스 테이블보다는 페이지 카운트, 책이름 순서인 인덱스 테이블이 필터링을 더 많이 거칠거라 예상했고 인덱스 순서를 변경하여 재생성한 결과 1초대에서 약 0.3초로 크게 개선되었습니다.

여기서 카운트 캐시를 적용하는 방식으로도 개선할 방법이 있지만, 검색 API에서는 검색 조건에 따라 시시각각 바뀌기 때문에 불가능합니다. 
또한, 카운트 테이블을 생성하는 방식도 같은 이유로 불가능합니다.

그래서 생각해보니 애초에 카운트 쿼리가 문제일 것이라고 생각이 들었기 때문에 한 가지 가정을 했습니다. 
대부분의 요청이 검색 버튼을 클릭하고, 페이지 버튼을 통한 조회 요청이 거의 없을 경우가 많을거라고 가정했습니다.

이럴 경우 검색 버튼을 클릭한 경우에만 Page 수를 고정하고 (카운트 쿼리는 발생하지 않게 하고), 
다음 페이지로 이동하기 위해 페이지 버튼을 클릭했을 때만 실제 페이지 count 쿼리를 발생시켜 정확한 페이지 수를 사용하게 하면 됩니다.

따라서 코드를 구현할 때 검색버튼 클릭 여부가 true 일 때 고정된 페이징 토탈 건수를 반환하고, 페이지버튼을 눌렀을 때는 카운트쿼리를 발생하는 식으로 수행했습니다.
하지만 UX상에서 동적으로 페이지 번호가 바뀌는 상황이 불가능하거나 검색버튼 보다 페이지 번호를 누르는 일이 많으면 이 방식 역시 좋은 방식은 아닙니다. 
그때는 첫 페이지만 카운트쿼리를 하고, 그 후엔 프론트 영역에서 카운트를 캐싱하고 보내주는 방식으로 해결할 수 있을 것 같습니다.  

또한 카운트쿼리와 페이징쿼리는 서로 선후관계가 중요하지않으므로 자바에서는 CompletableFuture와 같이 비동기처리를 해도 될 것같습니다.
```

### 전체적인 코드 구성과 설계, 구현 중에 특별히 신경 쓴 부분, 좋은 아이디어가 있는 곳이 있나요?

```text

```