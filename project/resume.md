## AgileHub

## Redis를 왜 사용했나요?

```text
JWT의 주요 문제때문에 사용했습니다.

JWT자체가 무상태이기 때문에 로그아웃이나 보안위협이 생기면 토큰을 무효화하기 어려웠습니다.
따라서 
로그아웃하거나 보안 위협이 감지된 토큰의 ID를 Redis에 저장하고, 
매 요청마다 이 블랙리스트를 체크했죠. 이렇게 하면 즉시 토큰을 무효화할 수 있었어요.

또
Access 토큰의 수명은 짧게(예: 15분), 
Refresh 토큰은 길게(예: 7일) 설정하고 Redis에 저장했어요. 
사용자 경험을 해치지 않으면서도 보안을 강화할 수 있었죠. 
Refresh 토큰으로 새 Access 토큰을 발급할 때마다 Redis의 정보를 업데이트했어요.

마지막으로 이메일 초대 구현을 할 때 
클라이언트가 요청할 사용자 이메일과 가입시킬 project 아이디를 전달하고
서버는 invitecode를 생성하여 레디스에 키는 invitecode, 값은 프로젝트 Id로 저장하고 TTL을 5분으로 설정했습니다.
그리고 SMTP를 통하여 이메일에 invitecode를 담아 전송하고, 사용자는 해당 invitecode로 클라이언트에 접속하면
 
클라이언트는 받은 invitecode를 서버에 post요청을 통해 보내고 서버는 해당 invitecode로 레디스에 조회하여  
ProjectId를 가져와 멤버를 프로젝트에 가입시켰습니다.
```

## 이메일 초대 구현

```text
이메일 초대 구현을 할 때 
클라이언트가 요청할 사용자 이메일과 가입시킬 project 아이디를 전달하고
서버는 invitecode를 생성하여 레디스에 키는 invitecode, 값은 프로젝트 Id로 저장하고 TTL을 5분으로 설정했습니다.
그리고 SMTP를 통하여 이메일에 invitecode를 담아 전송하고, 사용자는 해당 invitecode로 클라이언트에 접속하면
 
클라이언트는 받은 invitecode를 서버에 post요청을 통해 보내고 서버는 해당 invitecode로 레디스에 조회하여  
ProjectId를 가져와 멤버를 프로젝트에 가입시켰습니다.
```


## 드라이빙 테이블이 뭔가요?

```text
조인 쿼리에서 가장 먼저 읽히는 테이블로, 기준 테이블입니다.
```

## from에 서브쿼리를 사용했는 데 왜 조회속도가 단축되었나요?

```text
서브쿼리는 FROM 절 내에서 필터링된 데이터 또는 필요한 칼럼만을 미리 추출하는 역할을 합니다. 
즉, 서브쿼리에서 먼저 필터링하여 결과 집합을 작게 만든 뒤, 
그 결과에 대해 조인이나 다른 연산을 수행하므로, 최종적으로 조회해야 하는 데이터의 양이 줄어들게 됩니다.
```

## 서브 쿼리의 정의/종류/차이점?

```text
서브쿼리는 메인 쿼리의 일부분으로, 
SELECT, FROM, WHERE, HAVING, JOIN 등의 절에 포함될 수 있습니다. 
그리고 서브쿼리는 한 개의 값 또는 여러 값을 반환할 수 있습니다

단일 행 서브쿼리 , 다중 행 서브쿼리
위치관점으로는 상관 서브쿼리 vs 비상관 서브쿼리
```

## 서브쿼리가 왜 성능이 낮을까요?

```text
서브쿼리는 데이터베이스의 쿼리 최적화기가 인덱스를 효과적으로 사용하지 못할 가능성이 큽니다. 
특히 서브쿼리가 여러 테이블에서 데이터를 검색하는 경우, 
인덱스를 사용하는 대신 **풀 테이블 스캔(Full Table Scan)**이 발생할 수 있습니다. 
이로 인해 쿼리의 처리 속도가 느려질 수 있습니다.

또한,  서브쿼리가 큰 결과 집합을 제공하면 메모리사용량이 증가하면서 성능이 떨어집니다

해결방법으로는 JOIN 사용하면 효율적으로 처리되는 경우가 많습니다.
```

## QueryDsl이 from 절 사용이 불가능하다고 했는데 다른 해결 방법이 있는데 혹시 아시나요?

```text
- id검색 쿼리, 조회쿼리를 나눠서 실행합니다. 단, 이는 대용량 데이터를 조회할 때 DB마다의 MAX된 IN절 제한으로 불가능할 수도 있습니다.
- 네이티브쿼리, JDBC Template
- QueryDSL의 JPASQLQuery를 사용하여 네이티브 SQL과 유사한 기능을 구현할 수 있습니다. 
  단, from절 sub-query외부에서는 QClass의 형태로 참조가 불가능합니다.
```

## 네이티브 쿼리와 projection이 뭐죠?

```text
네이티브는 말 그대로 특정데이터베이스의 sql언어를 직접 string으로 작성하는거라 db에 종속적이고,
프로젝션은 dto를 통해 특정 칼럼만 받는 방식입니다. 
```

## Native Query와 Projection을 조합하는 방식을 도입했습니다. 에 대한 예시

```text
예를들어, 쿼리에서 에픽 ID와 관련된 스토리 수와 그 스토리들의 상태별인 DO,PROGRESS,DONE 각각의 카운트만을 가져오도록 하여 필요한 데이터만을 가져왔습니다.
```

##  테이블 간의 외래키 제약 조건을 설정한 이유와 그로인해 트레이드오프 

```text
외래키는 테이블 간의 참조 관계를 명확하게 정의하고, 데이터 무결성을 유지하는 데 중요한 역할을 합니다.
예를 들어, member_project 테이블에서 외래키로 project_id를 설정하면 해당 프로젝트가 삭제될 때
제약조건에 따라 함께 삭제되거나 삭제를 방지할 수 있습니다.

하지만
외래키가 설정된 경우, 데이터베이스는 참조 무결성을 유지하기 위해 
매번 해당 키가 유효한지 검사해야 하기 때문에, 삽입, 업데이트, 삭제 시 성능에 영향을 줄 수 있습니다.

또, 외래키로 여러 테이블이 서로 강하게 연결되면, 특정 테이블을 삭제하거나 변경할 때 
제약 조건으로 인해 복잡한 상황이 발생할 수 있습니다.

예를들면, project를 삭제할 때 관련된 member_project 데이터가 함께 삭제되어야 하는 상황에서, 
이를 처리하기 위해 순서가 중요하고, 강한 결합으로 인해 데이터 구조가 유연성을 잃을 수가 있습니다. 

따라서, 다음부터는 데이터를 설계할 때 왠만해서는 JPA 연관관계로 유지하고, 
데이터베이스에서는 외래키를 지양할 것 같습니다.  
```

## 엔티티 설계는 어떻게 하셨나요?

```text
의존성을 따지면서 설계했습니다. 

먼저 양방향 연관관계는 최소화 했습니다.
왜냐하면 A클래스가 B클래스를 의존하고 B클래스가 A클래스를 의존할때 A가 바뀔때 B도 바뀌고 B가 바뀔때 A도 바뀝니다. 
따라서 A와 B는 같이 움직이기 때문에 동기화에 신경써줘야 합니다. 

그래서 신경쓸게 너무 많아져 되도록 다대일 참조만 가지도록 설계했습니다.  

즉 의존관계가 사이클이 생기지 않도록 불필요한 의존관계를 제거하거나
단방향만 유지하도록 노력했습니다.
```

---

## Github Action vs Jenkins 차이점 장단점

```text
Github Action은 GitHub 리포지토리와 직접 연결되어 있어, pull request, commit, issue 등 GitHub 이벤트에 대해
특정 반응을 할 수가 있습니다.
또한, YAML 파일로 워크플로우를 정의하는데, 직관적이고 간단하게 사용할 수 있습니다.
그래서 GitHub 리포지토리에서 바로 설정과 관리가 가능합니다.

Jenkins는 다양한 플러그인 지원하기 때문에 확장이 매우 가능합니다. 예를들면 git과 연결하는 플러그인, junit 플러그인, 알림 플러그인 등이 있습니다.
또, 깃허브에 종속되지 않고 환경에 맞게 맞춤형으로 운영 가능합니다.
다만, 자체 서버를 운영해야 하고, 대규모 프로젝트에 적합한것 같습니다.
```

## self-hosted runners 왜 썼냐

```text
CI/CD 파이프라인을 구성하면서, AWS 서버의 SSH 프로토콜을 통해 접속하기 위해서는 
22번 포트를 전체 다에 열어둬야 깃허브 러너가 자동으로 배포가 가능했습니다.

하지만 22번 포트를 전체 다 연다는 것은 보안에 위험이 있기 때문에 이를 최소화 하기 위해 
self-hosted runners를 제안했습니다.

각자의 컴퓨터에 러너를 설치하고 배포할때마다 구동시켜서 배포하는 방식으로 했었는데,
동적으로 구동되고 있는 러너를 찾아서 그 러너를 통해 자동배포를 하도록 
YAML 파일을 작성할수가 없었고, 하나의 컴퓨터에만 러너를 설치하자니 그 역시 지속적 배포의 관점에 맞지 않았습니다.

따라서 self hosted runners를 하나의 자체 서버를 띄워 거기서 CD 역할을 맡도록 했습니다. 
그리고 웹애플리케이션 서버의 22번포트는 해당 self hosted runners의 서버의 주소에만 열도록 했습니다.
```

## 도커는 왜 사용했나요?

```text
도커 없이도 JAR로 배포/운영할 때 불편한 점이 거의 없었긴 해서 항상 왜 써야할까 고민이 많았습니다.

여러 장점이 있지만, 
가장 직접적으로 느꼈던 장점은 이미지에서 사용하고 있는 파일 계층은 디스크 공간 및 재사용 관점에서 효율적입니다.

예를들어 우분투는 Docker Hub에서 이미지를 가져오고 여러 이미지레이어로 이루어져 있습니다.
이때 이미지내에서 파일 시스템을 구성하는 레이어는 모두 읽기 전용입니다. 
도커의 이미지와 해당 파일 시스템은 읽기 전용이지만 해당 이미지를 컨테이너에 빌드되어 자체의 얇은 읽기 쓰기 레이어를 얻게 됩니다.
해당 컨테이너가 삭제되면 읽기 쓰기 가능한 얇은 컨테이너 레이어도 삭제됩니다.

물론 volume 설정을 통해 필요한 로그 데이터들은 호스트 내의 파일시스템에서 디렉토리를 마운트하여 데이터를 유지할 수 있게 합니다.

다시말해서 장점은 이미지에서 사용하고 있는 파일 계층은 디스크 공간 및 재사용 관점에서 효율적입니다. 
특정 이미지를 사용하여 여러개의 컨테이너르 만든다면 이 이미지에서 읽기전용인 파일시스템 구성은 다른 컨테이너에서 공유됩니다.
전체 파일 시스템 복사본을 만들필요 없기 때문에 디스크 공간을 효율적으로 사용하게됩니다. 
```

## 리버스 프록시는 왜 사용했죠?

```text
먼저 보안강화를 위해 사용했습니다. 
실제로 Nginx 로그를 확인해보니 무차별 악성 요청이 온걸 확인했습니다. 
nginx는 미리 설정해둔 필터링으로 직접 서버에 접근못하도록 하여 보호하고 있었습니다.
또한 리버스프록시에 WAF 구현도 할 수 있기떄문에 SQL 인젝션이나 XSS을 차단할 수 있습니다.

그리고 해당 서버에는 톰켓 뿐 아니라 프론트의 JS코드와 이미지 CSS도 있습니다.
리버스 프록시는 자주 사용되는 정적 파일들을 캐시에 저장하여 빠르게 제공할 수 있기 때문에 효과적이라 판단했습니다.

또한 API 게이트웨이 역할로, 웹 애플리케이션 서버의 포트번호와 주소를 숨기고 
요청을 포워딩해 서버의 구조를 외부에 노출하지 않도록 할 수 있습니다.

마지막으로 Nginx를 사용하면 무료 SSL 인증서인 **Let's Encrypt**를 쉽게 설정할 수 있습니다.
```

## Nginx 단점

```text
클라이언트와 서버 중간에 위치하다보니 3 way handshake 2번, 4 way hand shake 2번이 발생합니다.
따라서 성능이 저하됩니다.

또한 4-way handshaking 이 자주 발생한다면, 
대규모 트래픽이 발생한 경우 time wait 대기시간동안 
제거되지 않고 있는 소켓이 대거 발생할 수 있습니다.

이는 곧 로컬포트(local Port)가 고갈될 위험으로 이어지게 되죠.
대규모 트래픽이 발생해서 로컬포트가 고갈되는 경우, 
다시 로컬포트를 사용하고 싶어도 timewait 대기시간 60초가 지나고 나서야 다시 사용 가능해집니다. 
```


## Nginx 단점 해결방법

```text
Upstream 서버에 Keep alive를 설정해야합니다. 
따라서 한번만 TCP 세션에 연결하고 생존시간동안 동일한 세션에서 데이터를 
주고 받을 수 있도록 합니다.

결론적으로 불필요한 timewait 대기상태의 소켓이 생성되지 않게 막아줍니다.
```

## CDN이 뭔가요?

```text
CDN은 전 세계 여러 위치에 분산된 서버 네트워크로, 웹사이트의 콘텐츠를 캐싱(임시 저장)하고 제공합니다.

주요 이점으로는 
지연 시간 감소: 사용자와 가까운 서버에서 콘텐츠 제공
트래픽 분산: 여러 서버에 부하를 분산시켜 원본 서버의 부담 감소
보안 강화: DDoS 공격 등으로부터 보호 기능 제공
신뢰성 향상: 서버 장애 시 다른 서버로 자동 전환

사용 예:
대형 웹사이트: 아마존, 넷플릭스 등
뉴스 사이트: 갑작스러운 트래픽 증가 대응
게임 회사: 대용량 파일의 빠른 다운로드 제공
```

## MySQL왜 썼나요?

```text
팀원들이 MySQL에 대한 경험이 많아서 빠르게 적응할 수 있었고, 
러닝 커브가 낮아 프로젝트 초반에 효율적으로 DB 구조를 설계할 수 있었습니다.

프로젝트 특성상 높은 동시성이 필요한 상황은 아니었고, 데이터 정합성보다는 빠른 개발과 관리가 더 중요했습니다. 
그래서 ACID 특성을 엄격히 준수하는 PostgreSQL보다는 MySQL이 더 적합하다고 판단했습니다.
 MySQL의 InnoDB 엔진을 활용해 어느 정도의 정합성을 유지하면서도 성능을 최적화할 수 있었습니다
```



---


## BookChallenge

### 서버리소스를 늘렸는데 왜 유의미한 변화가 없었나요?
```text
각 트랜잭션이 사용하는 CPU 사용량이 0.05프로, 메모리 사용량을 5MB로 가정했을 때 TPS 200의 목표를 도달하기 위해서는 충분히 1CPU 1GB 램으로도 가능하다는 사실을 알게됐습니다.  
```

### 그 0.05랑 5MB는 어디서 혹은 어떻게 생각해서 나온 수치인가요?

```text
이 수치는 실제 트래픽 상황에서 각 트랜잭션의 평균적인 리소스 사용량을 추정한 값입니다. 이를 추정하기 위해서는 다음과 같은 과정을 거쳤습니다

CPU 사용량의 경우, 일반적으로 서버가 특정 요청을 처리하는 데 소요되는 CPU 자원을 모니터링한 후, NGrinder와 같은 부하 테스트 도구를 통해 트랜잭션 당 평균 CPU 사용량을 추정했습니다. 
다수의 요청을 처리하면서 평균적으로 각 트랜잭션이 0.05%의 CPU 자원을 소비한다는 결론을 얻었습니다.
 
주로 메모리 프로파일링 도구를 사용하여 트랜잭션 처리 시 사용되는 메모리 양을 측정했고, 각 트랜잭션 당 평균적으로 5MB 정도를 사용한다고 판단했습니다.
```

### filesort가 왜 성능이 안좋죠?

```text
filesort는 메모리 내에서 정렬을 처리하지 못할 때, 데이터를 디스크에 임시 파일로 저장한 후 정렬 작업을 수행합니다. 
메모리 접근보다 디스크 접근이 훨씬 느리기 때문에, 파일 시스템을 통해 정렬을 수행하는 것은 상당한 시간 지연을 유발합니다. 
```


### 커버링 인덱스가 뭔가요?

```text
커버링 인덱스는 실제 데이터 접근 과정 없이, 인덱스에 존재하는 칼럼 값으로만으로 쿼리를 완성하는 것을 이야기합니다.
쿼리 실행 계획에는  Extra 필드에 “Using Index”가 뜹니다. 

커버링 인덱스에는 SELECT,WHERE,GROUP BY 절등에서 사용할 수 있습니다.  
```

### 테이블 풀 스캔이 뭔가요?

```text
- 테이블에 속한 블록 전체를 읽어들여서 사용자 원하는 데이터를 찾습니다.
- 시퀀셜 액세스와 Multi Block I/O로 읽어들이고 

- 테이블 풀 스캔은 피해야한다는 인식이 있지만, 오히려 인덱스를 사용하는 것이 성능을 떨어뜨릴수 있습니다.
왜냐면
- 인덱스를 사용하면 랜덤 I/O가 발생할 수 있어, 많은 양의 데이터를 읽을 때 오히려 성능이 떨어질 수 있습니다.
- 특히 테이블의 대부분의 데이터를 읽어야 하는 경우, 
인덱스를 거쳐 데이터를 찾는 것보다 전체 테이블을 순차적으로 읽는 것이 더 빠를 수 있습니다.
```

### 인덱스 풀 스캔과 인덱스 레인지 스캔 차이가 뭐죠?

```text
인덱스 레인지 스캔 부터 설명드리면 
- 인덱스 선두 컬럼이 가공되지 않은 상태로 조건절에 있어야 Index Range Scan이 가능

- B+ Tree 인덱스 구조를 사용합니다. 

- MySQL의 InnoDB에서는 보조 인덱스에서 조건에 맞는 프라이머리 키를 찾고, 이를 통해 실제 테이블 레코드를 찾습니다

- 랜덤 액세스와 Single Block I/O를 사용합니다
따라서 소량의 데이터를 찾을 때 유용하지만 읽어야 할 데이터가 많아지면 오히려 Table Full Scan이 나을 수도 있습니다
왜냐면 캐시에서 못 찾으면 레코드 하나 읽기 위해 매번 IO Call을 해야되고, 그러므로 Table Full Scan 보다 불리합니다.

인덱스 풀 스캔은
- 인덱스 선두 칼럼이 조건절에 없으면 인덱스 레인지 스캔이 불가능하여 옵티마이저는 Table Full Scan을 고려하지만
대용량 테이블이면 그게 부담이기 때문에 인덱스 풀 스캔을 하게 됩니다.
왜냐면 인덱스 스캔을 통해 대부분의 레코드를 필터링하고 아주 일부만 접근할 수 있기 때문입니다.

하지만 어쩃든 다 읽는 거기 때문에 자주 접근하는 데이터면 인덱스 레인지 스캔이 되기 위해 인덱스 선두 칼럼을 두는 것이 좋습니다.
```

### B-Tree 와 B+Tree 차이점

```text
B-Tree는 
- 이진트리의 확장된 형태로 최대 N차 만큼의 자식을 가질 수 있습니다. 
- 또한 이진트리와 달리 트리가 균형있게 구성되기 때문에 최악의 경우에도 시간복잡도가 O(logn)입니다.
- 모든 노드(내부 노드와 리프 노드)에 키와 데이터를 저장합니다.
- 범위 검색 시 트리를 여러 번 탐색해야 함

B+Tree는 B-Tree의 변형 구조입니다.
- 오직 리프 노드에만 데이터 저장
따라서 모든 검색은 리프 노드까지 도달해야 완료됩니다
- 리프 노드가 연결리스트로 연결되어 있어 범위 검색이 매우 효율적입니다
-  내부 노드에는 데이터 대신 인덱스 키만 저장되므로 더 많은 인덱스 키를 저장할 수 있어, 
트리의 높이를 낮춰 성능을 향상시킵니다.
```

### <관리의 복잡성>과 <쓰기 작업의 성능 저하> 가 왜 발생하는지? == 너무 많은 인덱스 생성이 안좋은 이유 

```text
관리의 복잡성 이유는
데이터베이스 스키마가 변경될 때마다 관련된 인덱스도 수동으로 관리해야 합니다. 
이 과정에서 불필요하거나 중복된 인덱스를 식별하여 제거하는 작업이 필요합니다

그리고 쓰기 작업의 성능 저하 이유는 
삽입, 갱신, 삭제 시 모든 관련 인덱스가 업데이트되어야 합니다. 각 인덱스는 B+트리 구조를 사용하는 경우가 많고, 
이 구조는 삽입이나 삭제 시 재정렬이 필요하기 때문에 추가적인 I/O 비용이 발생하며, 
시간 복잡도도 **O(log n)**으로 증가하게 됩니다. 
따라서 인덱스가 많을수록 쓰기 작업의 성능 저하가 발생할 수 있습니다.
```

### 쓰기 작업 우회 방법

```text
- 배치삽입을 사용해서 전체 삽입이 끝난 후 인덱스를 한 번에 갱신할 수 있어 성능을 향상 시킬 수 있습니다.

- NoSQL 데이터베이스를 사용합니다.
MongoDB와 같은 분산형 데이터베이스는 쓰기 작업에 있어 빠른 성능을 제공하고, 인덱스로 인한 성능 병목을 회피할 수 있습니다. 
```

### MongoDB는 왜 빠른 성능을 제공하죠?

```text
MongoDB는 기본적으로 비동기 쓰기를 사용합니다. 
클라이언트가 쓰기 요청을 보내면 데이터베이스는 즉시 응답을 반환하고, 
실제 디스크 쓰기는 백그라운드에서 수행됩니다.
```


### No-OFFSET 방식의 단점은 뭐가 있을까요?

```text
- UI 단에서 페이지 번호로 요구하는 비즈니스 사항에서 무한스크롤로 방식인 No-OFFSET은 불가능합니다.
- 총 페이지 수를 계산하기 어렵기 때문에 사용자가 특정 페이지 번호로 직접 이동하기 어려울 수 있습니다.
```

### No-OFFSET 방식말고 더 개선할 점은 없을까요?  

```text
책 검색 API에서도 비슷한 요구사항인 페이징 처리가 필요했었는데, 이때는 OFFSET 방식으로 개선해보기로 정했습니다.

책 검색 API에서는 다양한 조건이 들어갑니다. 조건절에 여러개의 조건이 들어가면 성능이 급격히 안좋아지는 현상이 발생했습니다.

테이블 풀 스캔에 duration은 5.364 초 입니다. where 절의 책이름과 페이지수 칼럼 각각에 이미 인덱스를 생성한 상태에도 불구하고, 테이블 풀 스캔으로 진행되었습니다. 
당연하게도 조건이 한개일때는 적용되지만, 두개가 같이 들어가니 인덱스 테이블을 더이상 타지 않았습니다.

주로 책 이름과 페이지 카운트만 검색한다고 가정하고, 복합인덱스를 생성할 때 자주 검색되는 조건인 책 이름 칼럼을 앞 순위에 배치하여 생성하여 성능을 5초에서 1초대로 개선했습니다.
또한, 책이름, 페이지카운트 순서인 인덱스 테이블보다는 페이지 카운트, 책이름 순서인 인덱스 테이블이 필터링을 더 많이 거칠거라 예상했고 인덱스 순서를 변경하여 재생성한 결과 1초대에서 약 0.3초로 크게 개선되었습니다.

여기서 카운트 캐시를 적용하는 방식으로도 개선할 방법이 있지만, 검색 API에서는 검색 조건에 따라 시시각각 바뀌기 때문에 불가능합니다. 
또한, 카운트 테이블을 생성하는 방식도 같은 이유로 불가능합니다.

그래서 생각해보니 애초에 카운트 쿼리가 문제일 것이라고 생각이 들었기 때문에 한 가지 가정을 했습니다. 
대부분의 요청이 검색 버튼을 클릭하고, 페이지 버튼을 통한 조회 요청이 거의 없을 경우가 많을거라고 가정했습니다.

이럴 경우 검색 버튼을 클릭한 경우에만 Page 수를 고정하고 (카운트 쿼리는 발생하지 않게 하고), 
다음 페이지로 이동하기 위해 페이지 버튼을 클릭했을 때만 실제 페이지 count 쿼리를 발생시켜 정확한 페이지 수를 사용하게 하면 됩니다.

따라서 코드를 구현할 때 검색버튼 클릭 여부가 true 일 때 고정된 페이징 토탈 건수를 반환하고, 페이지버튼을 눌렀을 때는 카운트쿼리를 발생하는 식으로 수행했습니다.
하지만 UX상에서 동적으로 페이지 번호가 바뀌는 상황이 불가능하거나 검색버튼 보다 페이지 번호를 누르는 일이 많으면 이 방식 역시 좋은 방식은 아닙니다. 
그때는 첫 페이지만 카운트쿼리를 하고, 그 후엔 프론트 영역에서 카운트를 캐싱하고 보내주는 방식으로 해결할 수 있을 것 같습니다.  

또한 카운트쿼리와 페이징쿼리는 서로 선후관계가 중요하지않으므로 자바에서는 CompletableFuture와 같이 비동기처리를 해도 될 것같습니다.
```

### 당연하게도 조건이 한개일때는 적용되지만, 두개가 같이 들어가니 인덱스 테이블을 더이상 타지 않은 이유

```text
예를 들어, book_name과 page_count 두 컬럼에 각각 인덱스를 생성하면, 
book_name에 대한 검색에는 인덱스가 잘 작동하지만, 
page_count에 대한 조건까지 같이 처리하려면 인덱스가 이를 효율적으로 처리하지 못합니다. 
이는 두 번째 조건이 첫 번째 인덱스의 순서와 무관하기 때문입니다.

따라서 옵티마이저는 인덱스를 사용하는 것보다 테이블 풀 스캔이 더 효율적이라고 판단하게 됩니다.
```

### Explain 요소에 대해 설명해주세요

```text
- extra: Extra 필드는 옵티마이저가 동작하는데 대해서 우리에게 알려주는 힌트다. 
이 필드는 EXPLAIN을 사용해 옵티마이저의 행동을 파악할 때 아주 중요하다.
    - Distinct: 중복 제거 시
        - 결과 집합에서 중복된 행을 제거할 때 사용됩니다.
        - 성능에 영향을 줄 수 있으므로 필요한 경우에만 사용해야 합니다.
    - Using where: WHERE 절로 필터 시
        - 쿼리의 WHERE 절을 사용하여 결과를 필터링할 때 나타납니다.
        - 일반적으로 정상적인 동작을 나타냅니다.
    - Using temporary: 임시 테이블 사용 시
        - 쿼리 처리 중 임시 테이블이 생성될 때 나타납니다.
        - DISTINCT, GROUP BY, ORDER BY 등의 연산에서 자주 발생합니다.
        - 대량의 데이터를 처리할 때 성능에 영향을 줄 수 있습니다.
    - Using index: 커버링 인덱스 사용 시
        - 쿼리가 인덱스만을 사용하여 결과를 얻을 수 있을 때 나타납니다.
        - 테이블 데이터에 접근하지 않아도 되므로 매우 효율적입니다.
    - Using filesort: 정렬 시
        - MySQL이 결과를 정렬할 때 나타납니다.
        - 메모리나 디스크에서 추가적인 정렬 작업이 필요함을 의미합니다.
```

### Explain과 Explain Analyze 차이점 

```text
Explain:

쿼리 실행 계획만 보여줍니다.
실제로 쿼리를 실행하지 않습니다.
데이터베이스 옵티마이저가 예상하는 실행 계획을 제공합니다.
빠르게 실행되며, 데이터에 영향을 주지 않습니다.


Explain Analyze:

쿼리 실행 계획을 보여주고, 실제로 쿼리를 실행합니다.
실제 실행 시간, 각 단계에서 처리된 행 수 등 실제 성능 지표를 제공합니다.
더 정확한 정보를 제공하지만, 실제 쿼리를 실행하므로 시간이 더 걸립니다.
```

### like 절 %가 앞에 있으면 성능 저하 이유와 해결방법

```text
인덱스는 일반적으로 데이터를 정렬된 상태로 유지하며, 이를 기반으로 효율적으로 검색을 수행합니다. 
그러나 LIKE 절에서 와일드카드가 앞에 있을 때는 이러한 인덱스의 정렬된 특성을 사용할 수 없게 되어 성능 저하가 발생합니다
B+트리 같은 자료 구조에서 순차 탐새을 할 수가 없어 모든 레코드를 하나씬 스캔해야하기 때문입니다.게다가 범위검색도 불가능합니다. 


LIKE 조건에서 와일드카드(%)가 앞에 있는 경우 인덱스를 비효율적으로 사용할 수 있으므로, 
MySQL의 Full Text Search로 ngram 파서로, 검색 최소 글자수 1, 토큰 사이즈 수를 1로 설정했는데 이렇게 하면 캐시에 넣어야 할 데이터도 늘어나고, 오히려 탐색 성능이 저하됐습니다. 
그 이유가 더미데이터를 생성할 때 책이름이 Book Title 1,2,3 이렇게 규칙성이 있어 중복되는 게 많아 그런 것 같습니다.
```


---




# 대학생이 Jira를 처음 사용할 때 겪은 어려움은 뭐가 있나요?

```text
Jira는 다양한 기능과 옵션을 제공하는데, 이를 한 번에 이해하는 것은 쉽지 않습니다. 특히 처음 사용자는 이슈 유형, 백로그 관리, 에픽과 스프린트 등 용어 자체도 생소할 수 있습니다.
그리고 이슈 관리도 복잡하고, 팀 협업을 안해봤으면 이 협업도구의 기능에 대해 제대로 이해못해 어려움을 겪을 수 있습니다. 
```

## 백로그관리와 스프린트관리의 차이점이 뭐죠?

```text
백로그는 <장기적인 프로젝트의 전반적인 작업>을 관리하는 도구로, 제품 소유자가 주로 <우선순위>를 설정하고 관리합니다.

반면에, 스프린트 관리는 백로그에서 우선순위가 높은 작업을 <선택하여 일정 기간 동안 집중적으로 실행>하는 과정입니다. 
스프린트는 보통 <1주에서 4주 정도의 짧은 기간 동안 진행>되며, 이 기간 동안 팀은 사전에 설정된 목표를 달성하는 데 집중합니다. 

즉, 백로그 관리는 프로젝트의 <전체적인 작업 목록을 관리>하고, 스프린트 관리는 <단기 목표를 설정>하고 실행하는 과정이라고 말씀드릴 수 있습니다.
```

## 에픽, 스토리, 테스크 차이점이 뭐죠?

```text
에픽은 <가장 큰 단위>의 작업입니다. 
에픽은 하나의 <큰 목표>나 기능을 의미하며, 보통 <여러 스프린트>에 걸쳐 완성되는 <긴 작업>입니다.

스토리는 에픽을 세분화한 것으로, <사용자 관점에서 요구되는 특정 기능>이나 작업을 설명합니다. 
보통 <한 스프린트 내에서 완료할 수 있는 작업 단위>로, 사용자 경험에 초점을 맞추고 있습니다.

테스크는 스토리를 더 세부적으로 나눈 것입니다. 팀원들이 <스토리를 실제로 구현하기 위해 필요한 구체적인 작업들>이 테스크입니다.
테스크는 아주 세부적인 단위로, 실제 개발자나 팀원이 실행할 수 있는 수준의 작업을 의미합니다.
```


## 애자일 방법론이 뭐죠?

```text
애자일이란 우선 만들고 보여주고 평가를 받고 회고를 하며, 방향을 고쳐나가는 것을 반복하며 MVP를 개발하고 
이 과정을 모두가 함께 참여하며 누구나 볼 수 있게 이 과정을 시각화하면서 피드백 주기를 점점 짧게 만들고자 노력하는 것입니다.
```

## 컨플루언스에서 팀원들의 학습 부담을 경감하기 위해 지식공유를 했다는 데 또 다른 장점이 있을까요?

```text
노션은 자유도가 너무 높아서 팀원들끼리 일정 규칙을 만들지 않으면 너무 중구난방으로 만들어지고, 필요한 자료를 찾을 때 시간을 써야하는데, 
컨플루언스는 프로젝트관리와 문서정리 용도에 맞게 만들어져있고, 검색기능으로 필요한 문서를 쉽게 찾을 수가 있습니다.

지라와 통합하여 회의에서 나온 문서의 내용을 바로바로 드래그하여 이슈로 만들 수 있고, 이슈를 문서에 가져올 수 있는 등 장점이 있습니다.
문서공유도 링크복사로 쉽게 할 수 있고요 
```

## 컨플루언스와 지라 차이가 뭘까요?

```text
Jira는 주로 작업 관리(이슈, 스프린트, 백로그)와 프로젝트의 진행 상태 추적에 초점이 맞춰져 있습니다.
Confluence는 팀이 함께 문서를 작성하고 지식을 공유하는 데 중점을 두고 있습니다.

Jira와 Confluence는 자연스럽게 통합되어, Confluence에서 작성한 문서가 Jira에서 다루는 프로젝트나 이슈와 직접 연결될 수 있습니다. 예를 들어, 회의록에서 바로 Jira 이슈를 생성할 수 있죠.
```